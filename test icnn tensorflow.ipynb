{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "np.seterr(all='raise')\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "import setproctitle\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--save', type=str, default='work')\n",
    "    parser.add_argument('--nEpoch', type=int, default=100)\n",
    "    # parser.add_argument('--testBatchSz', type=int, default=2048)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    parser.add_argument('--model', type=str, default=\"picnn\",\n",
    "                        choices=['picnn', 'ficnn'])\n",
    "    parser.add_argument('--dataset', type=str, default=\"moons\",\n",
    "                        choices=['moons', 'circles', 'linear'])\n",
    "    parser.add_argument('--noncvx', action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    npr.seed(args.seed)\n",
    "    tf.set_random_seed(args.seed)\n",
    "\n",
    "    setproctitle.setproctitle('bamos.icnn.synthetic.{}.{}'.format(args.model, args.dataset))\n",
    "\n",
    "    save = os.path.join(os.path.expanduser(args.save),\n",
    "                        \"{}.{}\".format(args.model, args.dataset))\n",
    "    if os.path.isdir(save):\n",
    "        shutil.rmtree(save)\n",
    "    os.makedirs(save, exist_ok=True)\n",
    "\n",
    "    if args.dataset == \"moons\":\n",
    "        (dataX, dataY) = make_moons(noise=0.3, random_state=0)\n",
    "    elif args.dataset == \"circles\":\n",
    "        (dataX, dataY) = make_circles(noise=0.2, factor=0.5, random_state=0)\n",
    "        dataY = 1.-dataY\n",
    "    elif args.dataset == \"linear\":\n",
    "        (dataX, dataY) = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                                             random_state=1, n_clusters_per_class=1)\n",
    "        rng = np.random.RandomState(2)\n",
    "        dataX += 2 * rng.uniform(size=dataX.shape)\n",
    "    else:\n",
    "        assert(False)\n",
    "\n",
    "    dataY = dataY.reshape((-1, 1)).astype(np.float32)\n",
    "\n",
    "    nData = dataX.shape[0]\n",
    "    nFeatures = dataX.shape[1]\n",
    "    nLabels = 1\n",
    "    nXy = nFeatures + nLabels\n",
    "\n",
    "    config = tf.ConfigProto() #log_device_placement=False)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = Model(nFeatures, nLabels, sess, args.model, nGdIter=30)\n",
    "        model.train(args, dataX, dataY)\n",
    "\n",
    "def variable_summaries(var, name=None):\n",
    "    if name is None:\n",
    "        name = var.name\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope('stdev'):\n",
    "            stdev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.scalar_summary('stdev/' + name, stdev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, nFeatures, nLabels, sess, model, nGdIter):\n",
    "        self.nFeatures = nFeatures\n",
    "        self.nLabels = nLabels\n",
    "        self.sess = sess\n",
    "        self.model = model\n",
    "\n",
    "        self.trueY_ = tf.placeholder(tf.float32, shape=[None, nLabels], name='trueY')\n",
    "\n",
    "        self.x_ = tf.placeholder(tf.float32, shape=[None, nFeatures], name='x')\n",
    "        self.y0_ = tf.placeholder(tf.float32, shape=[None, nLabels], name='y')\n",
    "\n",
    "        if model == 'picnn':\n",
    "            f = self.f_picnn\n",
    "        elif model == 'ficnn':\n",
    "            f = self.f_ficnn\n",
    "\n",
    "        E0_ = f(self.x_, self.y0_)\n",
    "\n",
    "        lr = 0.01\n",
    "        momentum = 0.9\n",
    "\n",
    "        yi_ = self.y0_\n",
    "        Ei_ = E0_\n",
    "        vi_ = 0\n",
    "\n",
    "        for i in range(nGdIter):\n",
    "            prev_vi_ = vi_\n",
    "            vi_ = momentum*prev_vi_ - lr*tf.gradients(Ei_, yi_)[0]\n",
    "            yi_ = yi_ - momentum*prev_vi_ + (1.+momentum)*vi_\n",
    "            Ei_ = f(self.x_, yi_, True)\n",
    "\n",
    "        self.yn_ = yi_\n",
    "        self.energies_ = Ei_\n",
    "\n",
    "        self.mse_ = tf.reduce_mean(tf.square(self.yn_ - self.trueY_))\n",
    "\n",
    "        self.opt = tf.train.AdamOptimizer(0.001)\n",
    "        self.theta_ = tf.trainable_variables()\n",
    "        self.gv_ = [(g,v) for g,v in\n",
    "                    self.opt.compute_gradients(self.mse_, self.theta_)\n",
    "                    if g is not None]\n",
    "        self.train_step = self.opt.apply_gradients(self.gv_)\n",
    "\n",
    "        self.theta_cvx_ = [v for v in self.theta_\n",
    "                           if 'proj' in v.name and 'W:' in v.name]\n",
    "\n",
    "        self.makeCvx = [v.assign(tf.abs(v)/10.) for v in self.theta_cvx_]\n",
    "        self.proj = [v.assign(tf.maximum(v, 0)) for v in self.theta_cvx_]\n",
    "\n",
    "        # for g,v in self.gv_:\n",
    "        #     variable_summaries(g, 'gradients/'+v.name)\n",
    "\n",
    "        self.merged = tf.merge_all_summaries()\n",
    "        self.saver = tf.train.Saver(max_to_keep=0)\n",
    "\n",
    "    def train(self, args, dataX, dataY):\n",
    "        save = os.path.join(os.path.expanduser(args.save),\n",
    "                            \"{}.{}\".format(args.model, args.dataset))\n",
    "\n",
    "        nTrain = dataX.shape[0]\n",
    "\n",
    "        imgDir = os.path.join(save, 'imgs')\n",
    "        if not os.path.exists(imgDir):\n",
    "            os.makedirs(imgDir)\n",
    "\n",
    "        trainFields = ['iter', 'loss']\n",
    "        trainF = open(os.path.join(save, 'train.csv'), 'w')\n",
    "        trainW = csv.writer(trainF)\n",
    "        trainW.writerow(trainFields)\n",
    "\n",
    "        self.trainWriter = tf.train.SummaryWriter(os.path.join(save, 'train'),\n",
    "                                                  self.sess.graph)\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "        if not args.noncvx:\n",
    "            self.sess.run(self.makeCvx)\n",
    "\n",
    "        nParams = np.sum(v.get_shape().num_elements() for v in tf.trainable_variables())\n",
    "\n",
    "        meta = {'nTrain': nTrain, 'nParams': nParams, 'nEpoch': args.nEpoch}\n",
    "        metaP = os.path.join(save, 'meta.json')\n",
    "        with open(metaP, 'w') as f:\n",
    "            json.dump(meta, f, indent=2)\n",
    "\n",
    "        bestMSE = None\n",
    "        for i in range(args.nEpoch):\n",
    "            tflearn.is_training(True)\n",
    "\n",
    "            print(\"=== Epoch {} ===\".format(i))\n",
    "            start = time.time()\n",
    "\n",
    "            y0 = np.full(dataY.shape, 0.5)\n",
    "            _, trainMSE, yn = self.sess.run(\n",
    "                [self.train_step, self.mse_, self.yn_],\n",
    "                feed_dict={self.x_: dataX, self.y0_: y0, self.trueY_: dataY})\n",
    "            if not args.noncvx and len(self.proj) > 0:\n",
    "                self.sess.run(self.proj)\n",
    "\n",
    "            trainW.writerow((i, trainMSE))\n",
    "            trainF.flush()\n",
    "\n",
    "            print(\" + loss: {:0.5e}\".format(trainMSE))\n",
    "            print(\" + time: {:0.2f} s\".format(time.time()-start))\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                loc = \"{}/{:05d}\".format(imgDir, i)\n",
    "                self.plot(loc, dataX, dataY)\n",
    "\n",
    "            if bestMSE is None or trainMSE < bestMSE:\n",
    "                loc = os.path.join(save, 'best')\n",
    "                self.plot(loc, dataX, dataY)\n",
    "                bestMSE = trainMSE\n",
    "\n",
    "        trainF.close()\n",
    "\n",
    "    def f_ficnn(self, x, y, reuse=False):\n",
    "        fc = tflearn.fully_connected\n",
    "        xy = tf.concat(1, (x, y))\n",
    "\n",
    "        prevZ = None\n",
    "        for i, sz in enumerate([200, 200, 1]):\n",
    "            z_add = []\n",
    "\n",
    "            with tf.variable_scope('z_x{}'.format(i)) as s:\n",
    "                z_x = fc(xy, sz, reuse=reuse, scope=s, bias=True)\n",
    "                z_add.append(z_x)\n",
    "\n",
    "            if prevZ is not None:\n",
    "                with tf.variable_scope('z_z{}_proj'.format(i)) as s:\n",
    "                    z_z = fc(prevZ, sz, reuse=reuse, scope=s, bias=False)\n",
    "                    z_add.append(z_z)\n",
    "\n",
    "            if sz != 1:\n",
    "                z = tf.nn.relu(tf.add_n(z_add))\n",
    "            prevZ = z\n",
    "\n",
    "        return tf.contrib.layers.flatten(z)\n",
    "\n",
    "    def f_picnn(self, x, y, reuse=False):\n",
    "        fc = tflearn.fully_connected\n",
    "\n",
    "        prevZ, prevU = None, x\n",
    "        for layerI, sz in enumerate([200, 200, 1]):\n",
    "            if sz != 1:\n",
    "                with tf.variable_scope('u'+str(layerI)) as s:\n",
    "                    u = fc(prevU, sz, scope=s, reuse=reuse)\n",
    "                    u = tf.nn.relu(u)\n",
    "\n",
    "            z_add = []\n",
    "\n",
    "            if prevZ is not None:\n",
    "                with tf.variable_scope('z{}_zu_u'.format(layerI)) as s:\n",
    "                    prevU_sz = prevU.get_shape()[1].value\n",
    "                    zu_u = fc(prevU, prevU_sz, reuse=reuse, scope=s,\n",
    "                            activation='relu', bias=True)\n",
    "                with tf.variable_scope('z{}_zu_proj'.format(layerI)) as s:\n",
    "                    z_zu = fc(tf.multiply(prevZ, zu_u), sz, reuse=reuse, scope=s,\n",
    "                                bias=False)\n",
    "                z_add.append(z_zu)\n",
    "\n",
    "            with tf.variable_scope('z{}_yu_u'.format(layerI)) as s:\n",
    "                yu_u = fc(prevU, self.nLabels, reuse=reuse, scope=s, bias=True)\n",
    "            with tf.variable_scope('z{}_yu'.format(layerI)) as s:\n",
    "                z_yu = fc(tf.multiply(y, yu_u), sz, reuse=reuse, scope=s, bias=False)\n",
    "            z_add.append(z_yu)\n",
    "\n",
    "            with tf.variable_scope('z{}_u'.format(layerI)) as s:\n",
    "                z_u = fc(prevU, sz, reuse=reuse, scope=s, bias=True)\n",
    "            z_add.append(z_u)\n",
    "\n",
    "            z = tf.add_n(z_add)\n",
    "            if sz != 1:\n",
    "                z = tf.nn.relu(z)\n",
    "\n",
    "            prevU = u\n",
    "            prevZ = z\n",
    "\n",
    "        return tf.contrib.layers.flatten(z)\n",
    "\n",
    "    def plot(self, loc, dataX, dataY):\n",
    "        delta = 0.01\n",
    "        x_min, x_max = dataX[:, 0].min() - .5, dataX[:, 0].max() + .5\n",
    "        y_min, y_max = dataX[:, 1].min() - .5, dataX[:, 1].max() + .5\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 20),\n",
    "                             np.linspace(y_min, y_max, 20))\n",
    "        xxFlat = xx.ravel()\n",
    "        yyFlat = yy.ravel()\n",
    "        gridX = np.vstack((xxFlat, yyFlat)).T\n",
    "        y0 = np.full(gridX.shape[0], 0.5).reshape((-1, 1))\n",
    "        yn, = self.sess.run([self.yn_], feed_dict={self.x_: gridX, self.y0_: y0})\n",
    "        yn = np.clip(yn, 0., 1.)\n",
    "        zz = 1.-yn.reshape(xx.shape)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "        plt.axis([x_min, x_max, y_min, y_max])\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(bottom=0,top=1,left=0,right=1)\n",
    "        ax.set_autoscale_on(False)\n",
    "        ax.grid(False)\n",
    "        v = np.linspace(0.0, 1.0, 10, endpoint=True)\n",
    "        plt.contourf(xx, yy, zz, v, alpha=0.5, cmap=cm.bwr)\n",
    "        # plt.colorbar()\n",
    "        yFlat = dataY.ravel()\n",
    "        plt.scatter(dataX[yFlat == 0, 0], dataX[yFlat == 0, 1], color='red')\n",
    "        plt.scatter(dataX[yFlat == 1, 0], dataX[yFlat == 1, 1], color='blue')\n",
    "        for ext in ['png', 'pdf']:\n",
    "            plt.savefig('{}.{}'.format(loc, ext))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable u0/W already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"c:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"c:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-df2dcd1c2d63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'picnn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-201b0ce1fe5a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nFeatures, nLabels, sess, model, nGdIter)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_ficnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mE0_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my0_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-201b0ce1fe5a>\u001b[0m in \u001b[0;36mf_picnn\u001b[1;34m(self, x, y, reuse)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msz\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayerI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m                     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tflearn\\layers\\core.py\u001b[0m in \u001b[0;36mfully_connected\u001b[1;34m(incoming, n_units, activation, bias, weights_init, bias_init, regularizer, weight_decay, trainable, restore, reuse, scope, name)\u001b[0m\n\u001b[0;32m    155\u001b[0m         W = va.variable('W', shape=[n_inputs, n_units], regularizer=W_regul,\n\u001b[0;32m    156\u001b[0m                         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                         restore=restore)\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLAYER_VARIABLES\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_key_op'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tflearn\\variables.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, validate_shape, device, restore)\u001b[0m\n\u001b[0;32m     63\u001b[0m                                            \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                                            \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                                            validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m           use_resource=use_resource)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    662\u001b[0m                          \u001b[1;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 664\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable u0/W already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"c:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"c:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\data\\harvard\\cours\\cs282\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "model = Model(50, 2, tf.Session(), 'picnn', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
